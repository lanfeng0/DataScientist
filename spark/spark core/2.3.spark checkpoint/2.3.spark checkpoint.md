1.RDD的缓存机制

RDD通过cache方法或者persist方法可以将前面的计算结果缓存，但并不是立即缓存，而是在接下来调用Action类的算子的时候，该RDD将会被缓存在计算节点的内存中，并供后面使用。

注意：缓存结束后，不会产生新的RDD

缓存有可能丢失，或者存储存储于内存的数据由于内存不足而被删除，RDD的缓存容错机制保证了即使缓存丢失也能保证计算的正确执行。

使用缓存的条件：（或者说什么时候进行缓存）

(1)要求的计算速度快，对效率要求高的时候

(2)集群的资源要足够大，能容得下要被缓存的数据

(3)被缓存的数据会多次的触发Action（多次调用Action类的算子）

(4)先进行过滤，然后将缩小范围后的数据缓存到内存中

(1)网络基础（OSI模型、ip地址、TCP、UDP原理）

(2)通信（URL类、URI类、代理、http协议、http方法、cookie、URLConnection）

(3)Socket（客户端Socket、构造和连接Socket、ServerSocket、构造服务器Socket、获得服务器socket的有关信息、Socket选项）

(4)javaNIO(通道、缓存区、非阻塞、选择器)

2.CheckPoint机制（容错机制）

检查点（本质是通过将RDD写入高可用的地方（例如
hdfs）做检查点）是为了通过lineage（血统）做容错的辅助，lineage过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果之后有节点出现问题而丢失分区，从做检查点的RDD开始重做Lineage，就会减少开销。

设置checkpoint的目录，可以是本地的文件夹、也可以是HDFS。一般是在具有容错能力，高可靠的文件系统上(比如HDFS,
S3等)设置一个检查点路径，用于保存检查点数据。

在设置检查点之后，该RDD之前的有依赖关系的父RDD都会被销毁，下次调用的时候直接从检查点开始计算。

checkPoint和cache一样，都是通过调用一个Action类的算子才能运行。

checkPoint减少运行时间的原因：第一次调用检查点的时候，会产生两个executor，两个进程分别是从hdfs读文件和计算（调用的Action类的算子），在第二次调用的时候会发现，运行的时间大大减少，是由于第二次调用算子的时候，不会再从hdfs读文件，而读取的是缓存到的数据，同样是从hdfs上读取。

3.persist()与checkpoint()

rdd.persist(StorageLevel.DISK\_ONLY) 与 checkpoint
也有区别。前者虽然可以将 RDD 的 partition 持久化到磁盘，但该 partition
由 blockManager 管理。一旦 driver program 执行结束，也就是 executor
所在进程 CoarseGrainedExecutorBackend stop，blockManager 也会 stop，被
cache 到磁盘上的 RDD 也会被清空（整个 blockManager 使用的 local
文件夹被删除）。而 checkpoint 将 RDD 持久化到 HDFS
或本地文件夹，如果不被手动 remove 掉（ 话说怎么 remove checkpoint 过的
RDD？ ），是一直存在的，也就是说可以被下一个 driver program 使用，而
cached RDD 不能被其他 dirver program 使用。

实验

\[hadoop@h201 hadoop-2.7.2\]\$ bin/hadoop fs -mkdir /checkpoint

scala&gt; val rdd1 =sc.parallelize(1 to 10)

scala&gt; val rdd2 = rdd1.filter(x=&gt;x&gt;5)

查看血统

scala&gt; rdd2.toDebugString

res4: String =

\(1) MapPartitionsRDD\[1\] at filter at &lt;console&gt;:26 \[\]

| ParallelCollectionRDD\[0\] at parallelize at &lt;console&gt;:24 \[\]

声明checkpoint在HDFS上目录

scala&gt; sc.setCheckpointDir("hdfs://h201:9000/checkpoint")

scala&gt; rdd2.checkpoint

scala&gt; rdd2.collect()

查看hdfs目录（存在缓存文件）

\[hadoop@h201 hadoop-2.7.2\]\$ bin/hadoop fs -mkdir /checkpoint
