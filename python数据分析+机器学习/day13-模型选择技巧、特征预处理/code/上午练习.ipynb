{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测小麦种类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/seeds.csv',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.2210</td>\n",
       "      <td>5.220</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.0180</td>\n",
       "      <td>4.956</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.6990</td>\n",
       "      <td>4.825</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.2590</td>\n",
       "      <td>4.805</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.3550</td>\n",
       "      <td>5.175</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.38</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>5.386</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.4620</td>\n",
       "      <td>4.956</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.69</td>\n",
       "      <td>14.49</td>\n",
       "      <td>0.8799</td>\n",
       "      <td>5.563</td>\n",
       "      <td>3.259</td>\n",
       "      <td>3.5860</td>\n",
       "      <td>5.219</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.10</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>5.420</td>\n",
       "      <td>3.302</td>\n",
       "      <td>2.7000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.63</td>\n",
       "      <td>15.46</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>6.053</td>\n",
       "      <td>3.465</td>\n",
       "      <td>2.0400</td>\n",
       "      <td>5.877</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.44</td>\n",
       "      <td>15.25</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.884</td>\n",
       "      <td>3.505</td>\n",
       "      <td>1.9690</td>\n",
       "      <td>5.533</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>5.714</td>\n",
       "      <td>3.242</td>\n",
       "      <td>4.5430</td>\n",
       "      <td>5.314</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.03</td>\n",
       "      <td>14.16</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>5.438</td>\n",
       "      <td>3.201</td>\n",
       "      <td>1.7170</td>\n",
       "      <td>5.001</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.89</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.439</td>\n",
       "      <td>3.199</td>\n",
       "      <td>3.9860</td>\n",
       "      <td>4.738</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.78</td>\n",
       "      <td>14.06</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>5.479</td>\n",
       "      <td>3.156</td>\n",
       "      <td>3.1360</td>\n",
       "      <td>4.872</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.74</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.8744</td>\n",
       "      <td>5.482</td>\n",
       "      <td>3.114</td>\n",
       "      <td>2.9320</td>\n",
       "      <td>4.825</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.59</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>5.351</td>\n",
       "      <td>3.333</td>\n",
       "      <td>4.1850</td>\n",
       "      <td>4.781</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.99</td>\n",
       "      <td>13.83</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>5.119</td>\n",
       "      <td>3.383</td>\n",
       "      <td>5.2340</td>\n",
       "      <td>4.781</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15.69</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>5.527</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1.5990</td>\n",
       "      <td>5.046</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.70</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>5.205</td>\n",
       "      <td>3.466</td>\n",
       "      <td>1.7670</td>\n",
       "      <td>4.649</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.72</td>\n",
       "      <td>13.57</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>5.226</td>\n",
       "      <td>3.049</td>\n",
       "      <td>4.1020</td>\n",
       "      <td>4.914</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.16</td>\n",
       "      <td>14.40</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.129</td>\n",
       "      <td>3.0720</td>\n",
       "      <td>5.176</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.26</td>\n",
       "      <td>0.8722</td>\n",
       "      <td>5.520</td>\n",
       "      <td>3.168</td>\n",
       "      <td>2.6880</td>\n",
       "      <td>5.219</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.88</td>\n",
       "      <td>14.90</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>5.618</td>\n",
       "      <td>3.507</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>5.091</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.08</td>\n",
       "      <td>13.23</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>5.099</td>\n",
       "      <td>2.936</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>4.961</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15.01</td>\n",
       "      <td>14.76</td>\n",
       "      <td>0.8657</td>\n",
       "      <td>5.789</td>\n",
       "      <td>3.245</td>\n",
       "      <td>1.7910</td>\n",
       "      <td>5.001</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.19</td>\n",
       "      <td>15.16</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>5.833</td>\n",
       "      <td>3.421</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>5.307</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.02</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>5.395</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.3730</td>\n",
       "      <td>4.825</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.74</td>\n",
       "      <td>13.67</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>5.395</td>\n",
       "      <td>2.956</td>\n",
       "      <td>2.5040</td>\n",
       "      <td>4.869</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.18</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>5.541</td>\n",
       "      <td>3.221</td>\n",
       "      <td>2.7540</td>\n",
       "      <td>5.038</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13.45</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>5.516</td>\n",
       "      <td>3.065</td>\n",
       "      <td>3.5310</td>\n",
       "      <td>5.097</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>11.41</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>5.090</td>\n",
       "      <td>2.775</td>\n",
       "      <td>4.9570</td>\n",
       "      <td>4.825</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>12.46</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.8706</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.017</td>\n",
       "      <td>4.9870</td>\n",
       "      <td>5.147</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>5.240</td>\n",
       "      <td>2.909</td>\n",
       "      <td>4.8570</td>\n",
       "      <td>5.158</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>11.65</td>\n",
       "      <td>13.07</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>5.108</td>\n",
       "      <td>2.850</td>\n",
       "      <td>5.2090</td>\n",
       "      <td>5.135</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>12.89</td>\n",
       "      <td>13.77</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>5.495</td>\n",
       "      <td>3.026</td>\n",
       "      <td>6.1850</td>\n",
       "      <td>5.316</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>11.56</td>\n",
       "      <td>13.31</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>5.363</td>\n",
       "      <td>2.683</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>5.182</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>11.81</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>5.413</td>\n",
       "      <td>2.716</td>\n",
       "      <td>4.8980</td>\n",
       "      <td>5.352</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>10.91</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>5.088</td>\n",
       "      <td>2.675</td>\n",
       "      <td>4.1790</td>\n",
       "      <td>4.956</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.82</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>5.089</td>\n",
       "      <td>2.821</td>\n",
       "      <td>7.5240</td>\n",
       "      <td>4.957</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>10.59</td>\n",
       "      <td>12.41</td>\n",
       "      <td>0.8648</td>\n",
       "      <td>4.899</td>\n",
       "      <td>2.787</td>\n",
       "      <td>4.9750</td>\n",
       "      <td>4.794</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>10.93</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>5.046</td>\n",
       "      <td>2.717</td>\n",
       "      <td>5.3980</td>\n",
       "      <td>5.045</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>11.27</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>5.091</td>\n",
       "      <td>2.804</td>\n",
       "      <td>3.9850</td>\n",
       "      <td>5.001</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>11.87</td>\n",
       "      <td>13.02</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>5.132</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.5970</td>\n",
       "      <td>5.132</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>10.82</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>5.180</td>\n",
       "      <td>2.630</td>\n",
       "      <td>4.8530</td>\n",
       "      <td>5.089</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>12.11</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.8639</td>\n",
       "      <td>5.236</td>\n",
       "      <td>2.975</td>\n",
       "      <td>4.1320</td>\n",
       "      <td>5.012</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>12.80</td>\n",
       "      <td>13.47</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>5.160</td>\n",
       "      <td>3.126</td>\n",
       "      <td>4.8730</td>\n",
       "      <td>4.914</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>12.79</td>\n",
       "      <td>13.53</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>5.224</td>\n",
       "      <td>3.054</td>\n",
       "      <td>5.4830</td>\n",
       "      <td>4.958</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>13.37</td>\n",
       "      <td>13.78</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>5.320</td>\n",
       "      <td>3.128</td>\n",
       "      <td>4.6700</td>\n",
       "      <td>5.091</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>12.62</td>\n",
       "      <td>13.67</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>5.410</td>\n",
       "      <td>2.911</td>\n",
       "      <td>3.3060</td>\n",
       "      <td>5.231</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>12.76</td>\n",
       "      <td>13.38</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>5.073</td>\n",
       "      <td>3.155</td>\n",
       "      <td>2.8280</td>\n",
       "      <td>4.830</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>12.38</td>\n",
       "      <td>13.44</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>5.219</td>\n",
       "      <td>2.989</td>\n",
       "      <td>5.4720</td>\n",
       "      <td>5.045</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>12.67</td>\n",
       "      <td>13.32</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>4.984</td>\n",
       "      <td>3.135</td>\n",
       "      <td>2.3000</td>\n",
       "      <td>4.745</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11.18</td>\n",
       "      <td>12.72</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>5.009</td>\n",
       "      <td>2.810</td>\n",
       "      <td>4.0510</td>\n",
       "      <td>4.828</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>12.70</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>5.183</td>\n",
       "      <td>3.091</td>\n",
       "      <td>8.4560</td>\n",
       "      <td>5.000</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>12.37</td>\n",
       "      <td>13.47</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>5.204</td>\n",
       "      <td>2.960</td>\n",
       "      <td>3.9190</td>\n",
       "      <td>5.001</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.6310</td>\n",
       "      <td>4.870</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.3250</td>\n",
       "      <td>5.003</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.3150</td>\n",
       "      <td>5.056</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.5980</td>\n",
       "      <td>5.044</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.6370</td>\n",
       "      <td>5.063</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1       2      3      4       5      6         7\n",
       "0    15.26  14.84  0.8710  5.763  3.312  2.2210  5.220      Kama\n",
       "1    14.88  14.57  0.8811  5.554  3.333  1.0180  4.956      Kama\n",
       "2    14.29  14.09  0.9050  5.291  3.337  2.6990  4.825      Kama\n",
       "3    13.84  13.94  0.8955  5.324  3.379  2.2590  4.805      Kama\n",
       "4    16.14  14.99  0.9034  5.658  3.562  1.3550  5.175      Kama\n",
       "5    14.38  14.21  0.8951  5.386  3.312  2.4620  4.956      Kama\n",
       "6    14.69  14.49  0.8799  5.563  3.259  3.5860  5.219      Kama\n",
       "7    14.11  14.10  0.8911  5.420  3.302  2.7000  5.000      Kama\n",
       "8    16.63  15.46  0.8747  6.053  3.465  2.0400  5.877      Kama\n",
       "9    16.44  15.25  0.8880  5.884  3.505  1.9690  5.533      Kama\n",
       "10   15.26  14.85  0.8696  5.714  3.242  4.5430  5.314      Kama\n",
       "11   14.03  14.16  0.8796  5.438  3.201  1.7170  5.001      Kama\n",
       "12   13.89  14.02  0.8880  5.439  3.199  3.9860  4.738      Kama\n",
       "13   13.78  14.06  0.8759  5.479  3.156  3.1360  4.872      Kama\n",
       "14   13.74  14.05  0.8744  5.482  3.114  2.9320  4.825      Kama\n",
       "15   14.59  14.28  0.8993  5.351  3.333  4.1850  4.781      Kama\n",
       "16   13.99  13.83  0.9183  5.119  3.383  5.2340  4.781      Kama\n",
       "17   15.69  14.75  0.9058  5.527  3.514  1.5990  5.046      Kama\n",
       "18   14.70  14.21  0.9153  5.205  3.466  1.7670  4.649      Kama\n",
       "19   12.72  13.57  0.8686  5.226  3.049  4.1020  4.914      Kama\n",
       "20   14.16  14.40  0.8584  5.658  3.129  3.0720  5.176      Kama\n",
       "21   14.11  14.26  0.8722  5.520  3.168  2.6880  5.219      Kama\n",
       "22   15.88  14.90  0.8988  5.618  3.507  0.7651  5.091      Kama\n",
       "23   12.08  13.23  0.8664  5.099  2.936  1.4150  4.961      Kama\n",
       "24   15.01  14.76  0.8657  5.789  3.245  1.7910  5.001      Kama\n",
       "25   16.19  15.16  0.8849  5.833  3.421  0.9030  5.307      Kama\n",
       "26   13.02  13.76  0.8641  5.395  3.026  3.3730  4.825      Kama\n",
       "27   12.74  13.67  0.8564  5.395  2.956  2.5040  4.869      Kama\n",
       "28   14.11  14.18  0.8820  5.541  3.221  2.7540  5.038      Kama\n",
       "29   13.45  14.02  0.8604  5.516  3.065  3.5310  5.097      Kama\n",
       "..     ...    ...     ...    ...    ...     ...    ...       ...\n",
       "180  11.41  12.95  0.8560  5.090  2.775  4.9570  4.825  Canadian\n",
       "181  12.46  13.41  0.8706  5.236  3.017  4.9870  5.147  Canadian\n",
       "182  12.19  13.36  0.8579  5.240  2.909  4.8570  5.158  Canadian\n",
       "183  11.65  13.07  0.8575  5.108  2.850  5.2090  5.135  Canadian\n",
       "184  12.89  13.77  0.8541  5.495  3.026  6.1850  5.316  Canadian\n",
       "185  11.56  13.31  0.8198  5.363  2.683  4.0620  5.182  Canadian\n",
       "186  11.81  13.45  0.8198  5.413  2.716  4.8980  5.352  Canadian\n",
       "187  10.91  12.80  0.8372  5.088  2.675  4.1790  4.956  Canadian\n",
       "188  11.23  12.82  0.8594  5.089  2.821  7.5240  4.957  Canadian\n",
       "189  10.59  12.41  0.8648  4.899  2.787  4.9750  4.794  Canadian\n",
       "190  10.93  12.80  0.8390  5.046  2.717  5.3980  5.045  Canadian\n",
       "191  11.27  12.86  0.8563  5.091  2.804  3.9850  5.001  Canadian\n",
       "192  11.87  13.02  0.8795  5.132  2.953  3.5970  5.132  Canadian\n",
       "193  10.82  12.83  0.8256  5.180  2.630  4.8530  5.089  Canadian\n",
       "194  12.11  13.27  0.8639  5.236  2.975  4.1320  5.012  Canadian\n",
       "195  12.80  13.47  0.8860  5.160  3.126  4.8730  4.914  Canadian\n",
       "196  12.79  13.53  0.8786  5.224  3.054  5.4830  4.958  Canadian\n",
       "197  13.37  13.78  0.8849  5.320  3.128  4.6700  5.091  Canadian\n",
       "198  12.62  13.67  0.8481  5.410  2.911  3.3060  5.231  Canadian\n",
       "199  12.76  13.38  0.8964  5.073  3.155  2.8280  4.830  Canadian\n",
       "200  12.38  13.44  0.8609  5.219  2.989  5.4720  5.045  Canadian\n",
       "201  12.67  13.32  0.8977  4.984  3.135  2.3000  4.745  Canadian\n",
       "202  11.18  12.72  0.8680  5.009  2.810  4.0510  4.828  Canadian\n",
       "203  12.70  13.41  0.8874  5.183  3.091  8.4560  5.000  Canadian\n",
       "204  12.37  13.47  0.8567  5.204  2.960  3.9190  5.001  Canadian\n",
       "205  12.19  13.20  0.8783  5.137  2.981  3.6310  4.870  Canadian\n",
       "206  11.23  12.88  0.8511  5.140  2.795  4.3250  5.003  Canadian\n",
       "207  13.20  13.66  0.8883  5.236  3.232  8.3150  5.056  Canadian\n",
       "208  11.84  13.21  0.8521  5.175  2.836  3.5980  5.044  Canadian\n",
       "209  12.30  13.34  0.8684  5.243  2.974  5.6370  5.063  Canadian\n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:,:7]\n",
    "target = data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集的拆分(拆成三份，目的是为了让算法评分更稳定)\n",
    "X_train1,X_test1,y_train1,y_test1 = train_test_split(train,target,test_size=0.1,random_state=0)\n",
    "X_train2,X_test2,y_train2,y_test2 = train_test_split(train,target,test_size=0.2,random_state=0)\n",
    "X_train3,X_test3,y_train3,y_test3 = train_test_split(train,target,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knnclf 0.1 test score is 0.952381\n",
      "knnclf 0.2 test score is 0.857143\n",
      "knnclf 0.3 test score is 0.920635\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证 保证算法评分更稳定\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnclf = KNeighborsClassifier()\n",
    "\n",
    "print(\"knnclf 0.1 test score is %f\"%knnclf.fit(X_train1,y_train1).score(X_test1,y_test1))\n",
    "print(\"knnclf 0.2 test score is %f\"%knnclf.fit(X_train2,y_train2).score(X_test2,y_test2))\n",
    "print(\"knnclf 0.3 test score is %f\"%knnclf.fit(X_train3,y_train3).score(X_test3,y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# 处理文本分类时使用的算法模型\n",
    "# from sklearn.naive_bayes import MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装一个函数，函数功能是传入算法和数据集，打印出算法评分\n",
    "\n",
    "def predict_score(model,train,target):\n",
    "    model_name = str(model.__class__).split('.')[-1].rstrip(\"'>\")\n",
    "    \n",
    "    # 数据集的拆分(拆成三份，目的是为了让算法评分更稳定)\n",
    "    X_train1,X_test1,y_train1,y_test1 = train_test_split(train,target,test_size=0.1,random_state=1)\n",
    "    X_train2,X_test2,y_train2,y_test2 = train_test_split(train,target,test_size=0.2,random_state=1)\n",
    "    X_train3,X_test3,y_train3,y_test3 = train_test_split(train,target,test_size=0.3,random_state=1)\n",
    "    \n",
    "    # 使用模型进行训练\n",
    "    print(\"%s 0.1 test score is %f\"%(model_name,model.fit(X_train1,y_train1).score(X_test1,y_test1)))\n",
    "    print(\"%s 0.2 test score is %f\"%(model_name,model.fit(X_train2,y_train2).score(X_test2,y_test2)))\n",
    "    print(\"%s 0.3 test score is %f\"%(model_name,model.fit(X_train3,y_train3).score(X_test3,y_test3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建各种分类算法对象，比较评分情况\n",
    "logistic = LogisticRegression()\n",
    "tree = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "gaussion = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.1 test score is 0.952381\n",
      "LogisticRegression 0.2 test score is 0.976190\n",
      "LogisticRegression 0.3 test score is 0.920635\n",
      "DecisionTreeClassifier 0.1 test score is 0.952381\n",
      "DecisionTreeClassifier 0.2 test score is 1.000000\n",
      "DecisionTreeClassifier 0.3 test score is 0.936508\n",
      "SVC 0.1 test score is 0.952381\n",
      "SVC 0.2 test score is 0.952381\n",
      "SVC 0.3 test score is 0.904762\n",
      "GaussianNB 0.1 test score is 0.952381\n",
      "GaussianNB 0.2 test score is 0.928571\n",
      "GaussianNB 0.3 test score is 0.920635\n"
     ]
    }
   ],
   "source": [
    "# 使用函数预测\n",
    "predict_score(logistic,train,target)\n",
    "predict_score(tree,train,target)\n",
    "predict_score(svc,train,target)\n",
    "predict_score(gaussion,train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改进约会网站的匹配效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/datingTestSet.txt',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40920</td>\n",
       "      <td>8.326976</td>\n",
       "      <td>0.953952</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14488</td>\n",
       "      <td>7.153469</td>\n",
       "      <td>1.673904</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26052</td>\n",
       "      <td>1.441871</td>\n",
       "      <td>0.805124</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75136</td>\n",
       "      <td>13.147394</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38344</td>\n",
       "      <td>1.669788</td>\n",
       "      <td>0.134296</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72993</td>\n",
       "      <td>10.141740</td>\n",
       "      <td>1.032955</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35948</td>\n",
       "      <td>6.830792</td>\n",
       "      <td>1.213192</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42666</td>\n",
       "      <td>13.276369</td>\n",
       "      <td>0.543880</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67497</td>\n",
       "      <td>8.631577</td>\n",
       "      <td>0.749278</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35483</td>\n",
       "      <td>12.273169</td>\n",
       "      <td>1.508053</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50242</td>\n",
       "      <td>3.723498</td>\n",
       "      <td>0.831917</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63275</td>\n",
       "      <td>8.385879</td>\n",
       "      <td>1.669485</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5569</td>\n",
       "      <td>4.875435</td>\n",
       "      <td>0.728658</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>51052</td>\n",
       "      <td>4.680098</td>\n",
       "      <td>0.625224</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>77372</td>\n",
       "      <td>15.299570</td>\n",
       "      <td>0.331351</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43673</td>\n",
       "      <td>1.889461</td>\n",
       "      <td>0.191283</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>61364</td>\n",
       "      <td>7.516754</td>\n",
       "      <td>1.269164</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>69673</td>\n",
       "      <td>14.239195</td>\n",
       "      <td>0.261333</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250185</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28488</td>\n",
       "      <td>10.528555</td>\n",
       "      <td>1.304844</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6487</td>\n",
       "      <td>3.540265</td>\n",
       "      <td>0.822483</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>37708</td>\n",
       "      <td>2.991551</td>\n",
       "      <td>0.833920</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22620</td>\n",
       "      <td>5.297865</td>\n",
       "      <td>0.638306</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28782</td>\n",
       "      <td>6.593803</td>\n",
       "      <td>0.187108</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19739</td>\n",
       "      <td>2.816760</td>\n",
       "      <td>1.686209</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>36788</td>\n",
       "      <td>12.458258</td>\n",
       "      <td>0.649617</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.656418</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28567</td>\n",
       "      <td>9.968648</td>\n",
       "      <td>0.731232</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6808</td>\n",
       "      <td>1.364838</td>\n",
       "      <td>0.640103</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>41611</td>\n",
       "      <td>0.230453</td>\n",
       "      <td>1.151996</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>53711</td>\n",
       "      <td>12.149747</td>\n",
       "      <td>1.389088</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>64371</td>\n",
       "      <td>9.149678</td>\n",
       "      <td>0.874905</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>9289</td>\n",
       "      <td>9.666576</td>\n",
       "      <td>1.370330</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>60613</td>\n",
       "      <td>3.620110</td>\n",
       "      <td>0.287767</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>18338</td>\n",
       "      <td>5.238800</td>\n",
       "      <td>1.253646</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>22845</td>\n",
       "      <td>14.715782</td>\n",
       "      <td>1.503758</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>74676</td>\n",
       "      <td>14.445740</td>\n",
       "      <td>1.211160</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>34143</td>\n",
       "      <td>13.609528</td>\n",
       "      <td>0.364240</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>14153</td>\n",
       "      <td>3.141585</td>\n",
       "      <td>0.424280</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>9327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120947</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>18991</td>\n",
       "      <td>0.454750</td>\n",
       "      <td>1.033280</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>9193</td>\n",
       "      <td>0.510310</td>\n",
       "      <td>0.016395</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2285</td>\n",
       "      <td>3.864171</td>\n",
       "      <td>0.616349</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>9493</td>\n",
       "      <td>6.724021</td>\n",
       "      <td>0.563044</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2371</td>\n",
       "      <td>4.289375</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>13963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.437030</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2299</td>\n",
       "      <td>3.733617</td>\n",
       "      <td>0.698269</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>5262</td>\n",
       "      <td>2.002589</td>\n",
       "      <td>1.380184</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>4659</td>\n",
       "      <td>2.502627</td>\n",
       "      <td>0.184223</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>17582</td>\n",
       "      <td>6.382129</td>\n",
       "      <td>0.876581</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>27750</td>\n",
       "      <td>8.546741</td>\n",
       "      <td>0.128706</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>9868</td>\n",
       "      <td>2.694977</td>\n",
       "      <td>0.432818</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>18333</td>\n",
       "      <td>3.951256</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>3780</td>\n",
       "      <td>9.856183</td>\n",
       "      <td>0.329181</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>18190</td>\n",
       "      <td>2.068962</td>\n",
       "      <td>0.429927</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>11145</td>\n",
       "      <td>3.410627</td>\n",
       "      <td>0.631838</td>\n",
       "      <td>smallDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>68846</td>\n",
       "      <td>9.974715</td>\n",
       "      <td>0.669787</td>\n",
       "      <td>didntLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>26575</td>\n",
       "      <td>10.650102</td>\n",
       "      <td>0.866627</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>48111</td>\n",
       "      <td>9.134528</td>\n",
       "      <td>0.728045</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>43757</td>\n",
       "      <td>7.882601</td>\n",
       "      <td>1.332446</td>\n",
       "      <td>largeDoses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1         2           3\n",
       "0    40920   8.326976  0.953952  largeDoses\n",
       "1    14488   7.153469  1.673904  smallDoses\n",
       "2    26052   1.441871  0.805124   didntLike\n",
       "3    75136  13.147394  0.428964   didntLike\n",
       "4    38344   1.669788  0.134296   didntLike\n",
       "5    72993  10.141740  1.032955   didntLike\n",
       "6    35948   6.830792  1.213192  largeDoses\n",
       "7    42666  13.276369  0.543880  largeDoses\n",
       "8    67497   8.631577  0.749278   didntLike\n",
       "9    35483  12.273169  1.508053  largeDoses\n",
       "10   50242   3.723498  0.831917   didntLike\n",
       "11   63275   8.385879  1.669485   didntLike\n",
       "12    5569   4.875435  0.728658  smallDoses\n",
       "13   51052   4.680098  0.625224   didntLike\n",
       "14   77372  15.299570  0.331351   didntLike\n",
       "15   43673   1.889461  0.191283   didntLike\n",
       "16   61364   7.516754  1.269164   didntLike\n",
       "17   69673  14.239195  0.261333   didntLike\n",
       "18   15669   0.000000  1.250185  smallDoses\n",
       "19   28488  10.528555  1.304844  largeDoses\n",
       "20    6487   3.540265  0.822483  smallDoses\n",
       "21   37708   2.991551  0.833920   didntLike\n",
       "22   22620   5.297865  0.638306  smallDoses\n",
       "23   28782   6.593803  0.187108  largeDoses\n",
       "24   19739   2.816760  1.686209  smallDoses\n",
       "25   36788  12.458258  0.649617  largeDoses\n",
       "26    5741   0.000000  1.656418  smallDoses\n",
       "27   28567   9.968648  0.731232  largeDoses\n",
       "28    6808   1.364838  0.640103  smallDoses\n",
       "29   41611   0.230453  1.151996   didntLike\n",
       "..     ...        ...       ...         ...\n",
       "970  53711  12.149747  1.389088  largeDoses\n",
       "971  64371   9.149678  0.874905   didntLike\n",
       "972   9289   9.666576  1.370330  smallDoses\n",
       "973  60613   3.620110  0.287767   didntLike\n",
       "974  18338   5.238800  1.253646  smallDoses\n",
       "975  22845  14.715782  1.503758  largeDoses\n",
       "976  74676  14.445740  1.211160   didntLike\n",
       "977  34143  13.609528  0.364240  largeDoses\n",
       "978  14153   3.141585  0.424280  smallDoses\n",
       "979   9327   0.000000  0.120947  smallDoses\n",
       "980  18991   0.454750  1.033280  smallDoses\n",
       "981   9193   0.510310  0.016395  smallDoses\n",
       "982   2285   3.864171  0.616349  smallDoses\n",
       "983   9493   6.724021  0.563044  smallDoses\n",
       "984   2371   4.289375  0.012563  smallDoses\n",
       "985  13963   0.000000  1.437030  smallDoses\n",
       "986   2299   3.733617  0.698269  smallDoses\n",
       "987   5262   2.002589  1.380184  smallDoses\n",
       "988   4659   2.502627  0.184223  smallDoses\n",
       "989  17582   6.382129  0.876581  smallDoses\n",
       "990  27750   8.546741  0.128706  largeDoses\n",
       "991   9868   2.694977  0.432818  smallDoses\n",
       "992  18333   3.951256  0.333300  smallDoses\n",
       "993   3780   9.856183  0.329181  smallDoses\n",
       "994  18190   2.068962  0.429927  smallDoses\n",
       "995  11145   3.410627  0.631838  smallDoses\n",
       "996  68846   9.974715  0.669787   didntLike\n",
       "997  26575  10.650102  0.866627  largeDoses\n",
       "998  48111   9.134528  0.728045  largeDoses\n",
       "999  43757   7.882601  1.332446  largeDoses\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:,:3]\n",
    "target = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "from sklearn.preprocessing import Normalizer\n",
    "# 区间缩放\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 标准化\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = Normalizer().fit_transform(train)\n",
    "train2 = MinMaxScaler().fit_transform(train)\n",
    "train3 = StandardScaler().fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train,target,test_size=0.2,random_state=1)\n",
    "X_train1,X_test1,y_train1,y_test1 = train_test_split(train1,target,test_size=0.2,random_state=1)\n",
    "X_train2,X_test2,y_train2,y_test2 = train_test_split(train2,target,test_size=0.2,random_state=1)\n",
    "X_train3,X_test3,y_train3,y_test3 = train_test_split(train3,target,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_process(model,train,target):\n",
    "    # 特征预处理\n",
    "    train1 = Normalizer().fit_transform(train)\n",
    "    train2 = MinMaxScaler().fit_transform(train)\n",
    "    train3 = StandardScaler().fit_transform(train)\n",
    "    \n",
    "    # 拆分样本集\n",
    "    X_train,X_test,y_train,y_test = train_test_split(train,target,test_size=0.2,random_state=1)\n",
    "    X_train1,X_test1,y_train1,y_test1 = train_test_split(train1,target,test_size=0.2,random_state=1)\n",
    "    X_train2,X_test2,y_train2,y_test2 = train_test_split(train2,target,test_size=0.2,random_state=1)\n",
    "    X_train3,X_test3,y_train3,y_test3 = train_test_split(train3,target,test_size=0.2,random_state=1)\n",
    "    \n",
    "    # 模型跑分\n",
    "    score = model.fit(X_train,y_train).score(X_test,y_test)\n",
    "    score1 = model.fit(X_train1,y_train1).score(X_test1,y_test1)\n",
    "    score2 = model.fit(X_train2,y_train2).score(X_test2,y_test2)\n",
    "    score3 = model.fit(X_train3,y_train3).score(X_test3,y_test3)\n",
    "    # 获取模型名称\n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    print(\"%s no-process score is %f\"%(model_name,score))\n",
    "    print(\"%s Normalizer-process score is %f\"%(model_name,score1))\n",
    "    print(\"%s MinMaxScaler-process score is %f\"%(model_name,score2))\n",
    "    print(\"%s StandardScaler-process score is %f\"%(model_name,score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "logistic = LogisticRegression()\n",
    "tree = DecisionTreeClassifier()\n",
    "guassion = GaussianNB()\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier no-process score is 0.790000\n",
      "KNeighborsClassifier Normalizer-process score is 0.765000\n",
      "KNeighborsClassifier MinMaxScaler-process score is 0.940000\n",
      "KNeighborsClassifier StandardScaler-process score is 0.940000\n",
      "LogisticRegression no-process score is 0.620000\n",
      "LogisticRegression Normalizer-process score is 0.305000\n",
      "LogisticRegression MinMaxScaler-process score is 0.885000\n",
      "LogisticRegression StandardScaler-process score is 0.910000\n",
      "DecisionTreeClassifier no-process score is 0.960000\n",
      "DecisionTreeClassifier Normalizer-process score is 0.735000\n",
      "DecisionTreeClassifier MinMaxScaler-process score is 0.960000\n",
      "DecisionTreeClassifier StandardScaler-process score is 0.960000\n",
      "GaussianNB no-process score is 0.935000\n",
      "GaussianNB Normalizer-process score is 0.540000\n",
      "GaussianNB MinMaxScaler-process score is 0.935000\n",
      "GaussianNB StandardScaler-process score is 0.935000\n",
      "SVC no-process score is 0.315000\n",
      "SVC Normalizer-process score is 0.305000\n",
      "SVC MinMaxScaler-process score is 0.935000\n",
      "SVC StandardScaler-process score is 0.960000\n"
     ]
    }
   ],
   "source": [
    "feature_process(knn,train,target)\n",
    "feature_process(logistic,train,target)\n",
    "feature_process(tree,train,target)\n",
    "feature_process(guassion,train,target)\n",
    "feature_process(svc,train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "性别预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "final_weight       int64\n",
       "education         object\n",
       "education_num      int64\n",
       "marital_status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital_gain       int64\n",
       "capital_loss       int64\n",
       "hours_per_week     int64\n",
       "native_country    object\n",
       "salary            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/adults.txt')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[['occupation','hours_per_week','race']].copy()\n",
    "target = data['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adm-clerical', 'Exec-managerial', 'Handlers-cleaners',\n",
       "       'Prof-specialty', 'Other-service', 'Sales', 'Craft-repair',\n",
       "       'Transport-moving', 'Farming-fishing', 'Machine-op-inspct',\n",
       "       'Tech-support', '?', 'Protective-serv', 'Armed-Forces',\n",
       "       'Priv-house-serv'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用索引方式填充\n",
    "train['occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo',\n",
       "       'Other'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射字符串数据为数字\n",
    "def transform_occupation(x):\n",
    "    occ = train['occupation'].unique()\n",
    "    return np.argwhere(occ==x)[0,0]\n",
    "train['occupation'] = train['occupation'].map(transform_occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_race(x):\n",
    "    race = train['race'].unique()\n",
    "    return np.argwhere(race==x)[0,0]\n",
    "train['race'] = train['race'].map(transform_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupation</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32531</th>\n",
       "      <td>11</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32532</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32533</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32534</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32535</th>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32536</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32537</th>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32538</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32539</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32540</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32541</th>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32542</th>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32543</th>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32544</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32545</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32546</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32547</th>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32548</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32549</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32550</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32551</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32552</th>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32553</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32554</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       occupation  hours_per_week  race\n",
       "0               0              40     0\n",
       "1               1              13     0\n",
       "2               2              40     0\n",
       "3               2              40     1\n",
       "4               3              40     1\n",
       "5               1              40     0\n",
       "6               4              16     1\n",
       "7               1              45     0\n",
       "8               3              50     0\n",
       "9               1              40     0\n",
       "10              1              80     1\n",
       "11              3              40     2\n",
       "12              0              30     0\n",
       "13              5              50     1\n",
       "14              6              40     2\n",
       "15              7              45     3\n",
       "16              8              35     0\n",
       "17              9              40     0\n",
       "18              5              50     0\n",
       "19              1              45     0\n",
       "20              3              60     0\n",
       "21              4              20     1\n",
       "22              8              40     1\n",
       "23              7              40     0\n",
       "24             10              40     0\n",
       "25             10              40     0\n",
       "26              6              40     0\n",
       "27             11              60     2\n",
       "28              1              80     0\n",
       "29              6              40     0\n",
       "...           ...             ...   ...\n",
       "32531          11              99     2\n",
       "32532           3              60     0\n",
       "32533           1              50     2\n",
       "32534           0              39     0\n",
       "32535          12              35     1\n",
       "32536           1              55     0\n",
       "32537           6              46     1\n",
       "32538           3              45     1\n",
       "32539          11              10     0\n",
       "32540           0              40     0\n",
       "32541          11              32     1\n",
       "32542          11              25     0\n",
       "32543           3              48     0\n",
       "32544           4              30     4\n",
       "32545           0              20     0\n",
       "32546          10              40     0\n",
       "32547           9              40     0\n",
       "32548           3              60     0\n",
       "32549           0              40     0\n",
       "32550           6              50     0\n",
       "32551           2              40     3\n",
       "32552           5              45     0\n",
       "32553          10              11     2\n",
       "32554           1              40     0\n",
       "32555          12              40     0\n",
       "32556          10              38     0\n",
       "32557           9              40     0\n",
       "32558           0              40     0\n",
       "32559           0              20     0\n",
       "32560           1              40     0\n",
       "\n",
       "[32561 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "logistic = LogisticRegression()\n",
    "tree = DecisionTreeClassifier()\n",
    "guassion = GaussianNB()\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier no-process score is 0.700752\n",
      "KNeighborsClassifier Normalizer-process score is 0.683710\n",
      "KNeighborsClassifier MinMaxScaler-process score is 0.707355\n",
      "KNeighborsClassifier StandardScaler-process score is 0.713343\n"
     ]
    }
   ],
   "source": [
    "feature_process(knn,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression no-process score is 0.681406\n",
      "LogisticRegression Normalizer-process score is 0.669430\n",
      "LogisticRegression MinMaxScaler-process score is 0.680946\n",
      "LogisticRegression StandardScaler-process score is 0.681406\n"
     ]
    }
   ],
   "source": [
    "feature_process(logistic,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier no-process score is 0.740365\n",
      "DecisionTreeClassifier Normalizer-process score is 0.717488\n",
      "DecisionTreeClassifier MinMaxScaler-process score is 0.740212\n",
      "DecisionTreeClassifier StandardScaler-process score is 0.740212\n"
     ]
    }
   ],
   "source": [
    "feature_process(tree,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC no-process score is 0.739751\n",
      "SVC Normalizer-process score is 0.668509\n",
      "SVC MinMaxScaler-process score is 0.671273\n",
      "SVC StandardScaler-process score is 0.718102\n"
     ]
    }
   ],
   "source": [
    "feature_process(svc,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB no-process score is 0.668816\n",
      "GaussianNB Normalizer-process score is 0.654076\n",
      "GaussianNB MinMaxScaler-process score is 0.668816\n",
      "GaussianNB StandardScaler-process score is 0.668816\n"
     ]
    }
   ],
   "source": [
    "feature_process(gaussion,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.1 test score is 0.726435\n",
      "KNeighborsClassifier 0.2 test score is 0.700752\n",
      "KNeighborsClassifier 0.3 test score is 0.723718\n"
     ]
    }
   ],
   "source": [
    "# 从样本集拆分的角度比较算法优劣\n",
    "predict_score(knn,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.1 test score is 0.676696\n",
      "LogisticRegression 0.2 test score is 0.681406\n",
      "LogisticRegression 0.3 test score is 0.680111\n"
     ]
    }
   ],
   "source": [
    "predict_score(logistic,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 0.1 test score is 0.748235\n",
      "DecisionTreeClassifier 0.2 test score is 0.740826\n",
      "DecisionTreeClassifier 0.3 test score is 0.740506\n"
     ]
    }
   ],
   "source": [
    "predict_score(tree,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB 0.1 test score is 0.667792\n",
      "GaussianNB 0.2 test score is 0.668816\n",
      "GaussianNB 0.3 test score is 0.663220\n"
     ]
    }
   ],
   "source": [
    "predict_score(gaussion,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.1 test score is 0.740866\n",
      "SVC 0.2 test score is 0.739751\n",
      "SVC 0.3 test score is 0.739789\n"
     ]
    }
   ],
   "source": [
    "predict_score(svc,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择决策树算法，区间缩放来特征预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测病马死亡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = pd.read_table('../data/horseColicTraining.txt',header=None)\n",
    "test_samples = pd.read_table('../data/horseColicTest.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_samples.iloc[:,:21]\n",
    "y_train = train_samples[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_samples.iloc[:,:21]\n",
    "y_test = test_samples[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat((X_train,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.concat((y_train,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "logistic = LogisticRegression()\n",
    "svc = SVC(kernel='rbf')\n",
    "tree = DecisionTreeClassifier()\n",
    "gaussion = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_process(knn,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_process(logistic,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_process(svc,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_process(gaussion,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以使用区间缩放法来对特征进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_score(knn,train,target)\n",
    "predict_score(logistic,train,target)\n",
    "predict_score(svc,train,target)\n",
    "predict_score(tree,train,target)\n",
    "predict_score(gaussion,train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过观察，Logistic\\SVC\\Gaussian三种算法比较稳定，不受样本集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用区间所方法处理特征\n",
    "minMax_train = MinMaxScaler().fit_transform(train)\n",
    "# 拆分样本集\n",
    "X_train,X_test,y_train,y_test = train_test_split(minMax_train,target,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=800)\n",
    "svc.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(C=1)\n",
    "logistic.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussion = GaussianNB()\n",
    "gaussion.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit svc.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit gaussion.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
