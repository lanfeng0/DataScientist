{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    函数说明：打开并解析文件，对数据进行分类:1 代表不喜欢  2 魅力一般  3  魅力十足\n",
    "    Parameters：\n",
    "        filename - 文件名\n",
    "    Returns:\n",
    "        \n",
    "\"\"\"\n",
    "def file2matrix(filename):\n",
    "#     打开文件\n",
    "    fr=open(filename)\n",
    "#     读取文件中所有内容\n",
    "    arrayOLines=fr.readlines();\n",
    "#     display(arrayOLines)\n",
    "# 得到文件总行数\n",
    "    numberOfLines=len(arrayOLines);\n",
    "#     display(numberOfLines)\n",
    "#     返回值都是0的 numberOfLines行  3列的矩阵\n",
    "    returnMat=np.zeros((numberOfLines,3))\n",
    "#     display(returnMat)\n",
    "# 返回分类标签向量  把默认的didntLike smallDoses largeDoses变成对应的1,2,3数值\n",
    "    classLabeVector=[]\n",
    "#     行的索引\n",
    "    index = 0\n",
    "#     遍历读取出来的所有数据\n",
    "    for line in arrayOLines:\n",
    "#         删除每一行数据后面的 \\n  \n",
    "        line =line.strip()\n",
    "#         display(line)\n",
    "        listFromLine=line.split('\\t')\n",
    "#         display(listFromLine)\n",
    "        returnMat[index,:]=listFromLine[0:3]\n",
    "        if listFromLine[-1] == 'didntLike':\n",
    "            classLabeVector.append(1)\n",
    "        elif listFromLine[-1] == 'smallDoses':\n",
    "            classLabeVector.append(2)\n",
    "        elif listFromLine[-1] == 'largeDoses':\n",
    "            classLabeVector.append(3)\n",
    "        index+=1\n",
    "        \n",
    "    return returnMat, classLabeVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    函数说明:对数据进行归一化\n",
    "    Parameters：\n",
    "        dataSet - 特征矩阵\n",
    "    Returns：\n",
    "        normDataSet - 归一化后的特征矩阵\n",
    "        ranges - 数据范围\n",
    "        minVals - 数据最小值\n",
    "\"\"\"\n",
    "def autoNorm(dataSet):\n",
    "#     获取数据每一列的最小值\n",
    "    minVals=dataSet.min(0)\n",
    "#     display(minVals)\n",
    "#     获取数据每一列的最大值\n",
    "    maxVals=dataSet.max(0)\n",
    "#     display(maxVals)\n",
    "#     最大值跟最小值的范围\n",
    "    ranges=maxVals-minVals\n",
    "#     display(ranges)\n",
    "#     np.shape返回dataset矩阵的行列   然后创建一个值都是0的同样行列的矩阵\n",
    "    normDataSet=np.zeros(np.shape(dataSet))\n",
    "#     display(normDataSet)\n",
    "#     返回dataSet的行数\n",
    "    m=dataSet.shape[0]\n",
    "#     display(m)\n",
    "#     原始值减去每一列的最小值\n",
    "    normDataSet=dataSet-np.tile(minVals,(m,1))\n",
    "#     display(np.tile(ranges,(m,1)))\n",
    "#   除以最大值和最小值的差  得到归一化的数据\n",
    "    normDataSet=normDataSet/np.tile(ranges,(m,1))\n",
    "#     display(normDataSet)\n",
    "    return normDataSet,ranges,minVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def classify1(inx,dataSet,labels,k):\n",
    "#     display([inx],dataSet,np.array(labels))\n",
    "    knn=KNeighborsClassifier()\n",
    "    knn.fit(dataSet,np.array(labels))\n",
    "    res=knn.predict([inx])\n",
    "#     res=knn.predict(inx)\n",
    "    display(res[0])\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    函数说明：\n",
    "        通过输入一个人的三围特征，进行分类输出\n",
    "\"\"\"\n",
    "def classifyPer():\n",
    "#     输出结果\n",
    "    resultList=['讨厌','有点喜欢','非常喜欢']\n",
    "#     特征输入\n",
    "    precentTats=float(input(\"玩视频游戏所耗时间百分比:\"))\n",
    "    ffMiles=float(input(\"每年出行里程数:\"))\n",
    "    iceCream=float(input(\"每周消耗的冰淇淋升数:\"))\n",
    "#     precentTats=4.875435\n",
    "#     ffMiles=5569\n",
    "#     iceCream=0.728658\n",
    "#     打开的文件名\n",
    "    filename=\"datingTestSet.txt\"\n",
    "#     调用file2matrix函数\n",
    "    datingDataMat,datingLabels=file2matrix(filename)\n",
    "#   训练集归一化  \n",
    "    normMat,ranges,minVals=autoNorm(datingDataMat)\n",
    "#     display(normMat,ranges,minVals)\n",
    "#     将测试集生成numpy数组\n",
    "    inArr=np.array([ffMiles,precentTats,iceCream])\n",
    "#     display(inArr)\n",
    "#     测试集归一化\n",
    "    norminArr=(inArr-minVals)/ranges\n",
    "#     display(norminArr)\n",
    "#   返回的分类结果  1  2  3\n",
    "#     classifierResult=classify0(norminArr,normMat,datingLabels,3)\n",
    "#     display(np.array(datingLabels))\n",
    "    classifierResult=classify1(norminArr,normMat,datingLabels,3)\n",
    "    display(classifierResult)\n",
    "#     打印下结果\n",
    "    print(\"你可能%s这个人\"%(resultList[classifierResult-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "玩视频游戏所耗时间百分比:10\n",
      "每年出行里程数:40000\n",
      "每周消耗的冰淇淋升数:0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你可能非常喜欢这个人\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    classifyPer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
